{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import zipfile\n",
    "import difflib\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_page(query):\n",
    "    \n",
    "    '''\n",
    "    Method to read the page from an html query, and to handle connection errors.\n",
    "    \n",
    "    In case of a connection error, will retry every 10 seconds for five minutes.\n",
    "    \n",
    "    This method will abort the program if connection cannot be established after 5 minutes.\n",
    "    \n",
    "    Input: query (HTML query requesting a particular page)\n",
    "    Output: page (HTML contents from requested page)\n",
    "    '''\n",
    "    \n",
    "    page = ''\n",
    "    \n",
    "    try:\n",
    "        client = uReq(query)\n",
    "        page = client.read()\n",
    "        client.close()\n",
    "    except: # in case of connection error from uReq(query)\n",
    "        retries = 0\n",
    "        while(retries < 30 and len(page) == 0):\n",
    "            print('Connection error... waiting 10 seconds...')\n",
    "            time.sleep(10) # wait 10 seconds\n",
    "            # try again\n",
    "            try:\n",
    "                print('Retrying...')\n",
    "                client = uReq(query)\n",
    "                page = client.read()\n",
    "            except:\n",
    "                retries += 1\n",
    "        if retries >= 30 and len(page) == 0: # exit the program\n",
    "            sys.exit('Cannot reach page after trying for 5 minutes.\\nAborting program...')\n",
    "            \n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# download zip archive containing list of accredited US Universities\n",
    "source_url = 'https://ope.ed.gov/accreditation/dataFiles/Accreditation_2017_04.zip'\n",
    "curr_folder = %pwd\n",
    "dest_filename = curr_folder + '\\Accreditation_2017_04.zip'\n",
    "urlretrieve(source_url, dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract contents of zip archive\n",
    "filename = dest_filename.split('\\\\')[-1]\n",
    "\n",
    "with zipfile.ZipFile(filename) as zf:\n",
    "    zf.extractall(curr_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read file\n",
    "accred_file = 'Accreditation_04_2017.csv'\n",
    "colleges = pd.read_csv(accred_file)\n",
    "\n",
    "# select unique college names\n",
    "college_list = colleges['Institution_Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Web Scraping Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "college_count = 0\n",
    "\n",
    "book = openpyxl.Workbook()\n",
    "sheet = book.get_active_sheet()\n",
    "file_name = 'college_stats1.xlsx'\n",
    "\n",
    "row_number = 1 # 1st row in excel sheet\n",
    "\n",
    "#write header row\n",
    "header = ['Institution', 'Program', 'Decision', 'Decision_medium', 'Status', 'Date', 'GPA', 'GRE_v', 'GRE_q', 'GRE_w', 'GRE_subj']\n",
    "cols = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']\n",
    "for col_index in range(len(header)):\n",
    "    cell = cols[col_index] + str(row_number)\n",
    "    sheet[cell].value = header[col_index]\n",
    "\n",
    "for college in college_list:\n",
    "        \n",
    "    college_count += 1\n",
    "    \n",
    "    # create new file for query results for every 1000 colleges\n",
    "    if college_count%1000 == 0:\n",
    "        \n",
    "        book.save(file_name) # save previous excel workbook\n",
    "        book = openpyxl.Workbook() # open new workbook\n",
    "        sheet = book.get_active_sheet()\n",
    "        # set new filename\n",
    "        file_name = 'college_stats' + str((college_count/1000) + 1) + '.xlsx'\n",
    "        # reset row_number and write header line into the new file\n",
    "        row_number = 1\n",
    "        for col_index in range(len(header)):\n",
    "            cell = cols[col_index] + str(row_number)\n",
    "            sheet[cell].value = header[col_index]\n",
    "\n",
    "    # in case of spaces in the school name, replace spaces with '%20' (to avoid http query error)\n",
    "    search_query = college.replace(' ', '%20')\n",
    "\n",
    "    # visit 1st result page for this college's query and extract total number of result pages\n",
    "    # -------------------\n",
    "    college_query = 'http://thegradcafe.com/survey/index.php?q=' + search_query\n",
    "    page = get_page(college_query)\n",
    "    page_soup = soup(page, \"html.parser\")\n",
    "\n",
    "    # try to extract number of pages of results returned. If no results, move on to next college query\n",
    "    try:\n",
    "        pagination = page_soup.find('div', attrs = {'class': re.compile('pagination')})\n",
    "        num_pages = int(pagination.text.split(' ')[4])\n",
    "    except:\n",
    "        print('School {}: {}... no search results.\\n'.format(college_count, college))\n",
    "        continue\n",
    "    # -------------------\n",
    "\n",
    "    # scrape data of interest from each result page\n",
    "    print('School {}: {}'.format(college_count, college))\n",
    "    print('Number of search result pages: {}'.format(num_pages))\n",
    "    \n",
    "    for p in range(1, num_pages + 1):\n",
    "        print('Page {}...'.format(p), end = ' ')\n",
    "        page_query = college_query + '&t=a&o=&p=' + str(p)\n",
    "        page = get_page(page_query)\n",
    "        page_soup = soup(page, \"html.parser\")\n",
    "\n",
    "        # ------------------- Begin reading of relevant page content -----------------------------\n",
    "        for coll in page_soup.findAll('td', attrs = {'class': re.compile('instcol')})[1:]: # skip [0]: header on each page\n",
    "            items = coll.find_next_siblings()[:-1] #drop the 'Comments' column (not needed)\n",
    "            items.append(coll)\n",
    "\n",
    "            row_number += 1 # start writing data from next row\n",
    "            current_row = str(row_number)\n",
    "\n",
    "            # for each record, write Institution, Program, Decision, Decision_Medium, Status, Date, gpa, gre_v, gre_q, gre_w, gre_subj\n",
    "            try:\n",
    "                sheet['A' + current_row].value = items[-1].text # Institution or College Name\n",
    "                sheet['B' + current_row].value = items[0].text # Program\n",
    "\n",
    "                decision = items[1].text.split('via')\n",
    "                sheet['C' + current_row].value = decision[0].strip(' ') # actual decision (accepted, rejected, wait listed, etc)\n",
    "                sheet['D' + current_row].value = decision[1].strip(' ').split(' ')[0] # decision medium (via email, phone, etc)\n",
    "\n",
    "                sheet['E' + current_row].value = items[2].text # Applicant status\n",
    "                sheet['F' + current_row].value = items[3].text # Date of decision\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if 'Undergrad GPA' in items[1].text: # extract gpa and GRE scores\n",
    "                scores = items[1].text.split('GRE')\n",
    "                gpa = scores[0].split(':')[1].strip(' ')\n",
    "                gre_scores = scores[1].split(':')[1].strip(' ')\n",
    "                gre_v, gre_q, gre_w = gre_scores.split('/')\n",
    "                gre_subj = scores[2].split(':')[1][:-1].strip(' ')\n",
    "\n",
    "                sheet['G' + current_row].value = gpa\n",
    "                sheet['H' + current_row].value = gre_v\n",
    "                sheet['I' + current_row].value = gre_q\n",
    "                sheet['J' + current_row].value = gre_w\n",
    "                sheet['K' + current_row].value = gre_subj\n",
    "            else: # move on to next line\n",
    "                pass\n",
    "#                 college_stats.write('\\n')\n",
    "        # -------------------- End reading of relevant page content -----------------------------\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "print('{} schools processed!'.format(college_count))\n",
    "\n",
    "book.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# current_dir = %pwd\n",
    "# data_files = [file for file in os.listdir(current_dir) if file.split('_')[0] == 'college']\n",
    "\n",
    "file1 = pd.read_excel('college_stats1.xlsx')\n",
    "print('file1 read')\n",
    "file2 = pd.read_excel('college_stats2.xlsx')\n",
    "print('file2 read')\n",
    "file3 = pd.read_excel('college_stats3.xlsx')\n",
    "print('file3 read')\n",
    "file4 = pd.read_excel('college_stats4.xlsx')\n",
    "print('file4 read')\n",
    "file5 = pd.read_excel('college_stats5.xlsx')\n",
    "print('file5 read')\n",
    "file6 = pd.read_excel('college_stats6.xlsx')\n",
    "print('file6 read')\n",
    "file7 = pd.read_excel('college_stats7.xlsx')\n",
    "print('file7 read')\n",
    "file8 = pd.read_excel('college_stats8.xlsx')\n",
    "print('file8 read')\n",
    "file9 = pd.read_excel('college_stats9.xlsx')\n",
    "print('file9 read')\n",
    "file10 = pd.read_excel('college_stats10.xlsx')\n",
    "print('file10 read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Merge and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge data\n",
    "college_data = pd.concat([file1, file2, file3, file4, file5, file6, file7, file8, file9, file10], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop all rows that have no Institution name\n",
    "college_data = college_data[college_data.Institution.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop any duplicate rows\n",
    "college_data = college_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert Date column to datetime\n",
    "college_data.Date = pd.to_datetime(college_data.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert a 'Year' column\n",
    "college_data['Year'] = college_data.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove stray website formatting strings found in 'Program' colums\n",
    "prog_list = college_data.Program.values\n",
    "for index in range(len(prog_list)):\n",
    "    if 'Onmouseover' in prog_list[index]:\n",
    "        prog_list[index] = (prog_list[index].split('\"')[-1]).strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract program, degree and semester information from prog_list\n",
    "program, degree, semester = [], [], []\n",
    "for item in prog_list:\n",
    "    try:\n",
    "        program.append(' '.join(item[:-6].split()[:-1])[:-1])\n",
    "        degree.append(item[:-6].split()[-1])\n",
    "        semester.append(item[-4])\n",
    "    except:\n",
    "        if len(degree) < len(program): # error was thrown at degree\n",
    "            degree.append(np.nan)\n",
    "        if len(semester) < len(degree): # error was thrown at semester\n",
    "            semester.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert program, degree and semester into college_data\n",
    "college_data.Program = program\n",
    "college_data.insert(loc = 2, column = 'Degree', value = degree)\n",
    "college_data.insert(loc = 3, column = 'Semester', value = semester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "college_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Status description:\n",
    "\n",
    "- A: American Student\n",
    "- U: International student with US degree\n",
    "- I: International student without US degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"plot1\"></a>\n",
    "#### Plot 1: Acceptance Rate per degree by immigrant status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_status = college_data[college_data.Status.isin(['A', 'I', 'U'])]\n",
    "accepted = valid_status[valid_status.Decision == 'Accepted']\n",
    "\n",
    "acc_rate = 100 * accepted.Status.groupby(accepted.Degree).value_counts().div(valid_status.Status.groupby(valid_status.Degree).value_counts())\n",
    "\n",
    "phd = acc_rate.loc['PhD']\n",
    "masters = acc_rate.loc['Masters']\n",
    "mfa = acc_rate.loc['MFA']\n",
    "mba = acc_rate.loc['MBA']\n",
    "\n",
    "rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "phd.plot(kind = 'bar')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.title('PhD Acceptance Rate by Imigrant Status')\n",
    "plt.ylabel('Acceptance Rate (%)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "masters.plot(kind = 'bar')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.title('Masters Acceptance Rate by Imigrant Status')\n",
    "plt.ylabel('Acceptance Rate (%)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "mfa.plot(kind = 'bar')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.title('MFA Acceptance Rate by Imigrant Status')\n",
    "plt.ylabel('Acceptance Rate (%)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "mba.plot(kind = 'bar')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.title('MBA Acceptance Rate by Imigrant Status')\n",
    "plt.ylabel('Acceptance Rate (%)')\n",
    "\n",
    "# plt.legend(['A', 'I', 'U'],['American', 'Int (no US deg)', 'Int (US deg)'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is interesting, showing for example that US colleges generally tend to accept more international students for MFA and MBA programs.\n",
    "\n",
    "However, we can drill down further into the data to gain more meaningful insights. Let us imagine an international student without a US degree who wants to pursue a PhD in Biostatistics. This student scored 155 on the GRE quantitative section. Based on our data, we can present a list colleges, ranked in order of acceptance rate for international students applying for a PhD in Biostatistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"plot2\"></a>\n",
    "#### Plot 2: Acceptance rates for international students applying for a PhD in Biostatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "GRE scores were rescaled after 2011, but students were reporting on both old and new scales until 2013. We will filter our data to only include GRE scores within the new scale, and between 2013 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_gre_v = college_data[college_data.GRE_v <= 170]\n",
    "new_gre_q = college_data[college_data.GRE_q <= 166]\n",
    "\n",
    "new_gre_v = new_gre_v[new_gre_v.Year.isin([2013, 2014, 2015, 2016, 2017])]\n",
    "new_gre_q = new_gre_q[new_gre_q.Year.isin([2013, 2014, 2015, 2016, 2017])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we are interested in good-quality colleges, we can select colleges that accept GRE quantitative scores greater than or equal to this student's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "your_greq_score = 155\n",
    "your_colleges = new_gre_q[new_gre_q.GRE_q >= your_greq_score]\n",
    "\n",
    "int_filter = your_colleges[your_colleges.Status == 'I']\n",
    "int_accepted = int_filter[(int_filter.Decision == 'Accepted') & (int_filter.Program == 'Biostatistics') & (int_filter.Degree == 'PhD')]\n",
    "acceptance_rate = 100 * int_accepted.Institution.groupby(int_accepted.Status).value_counts().div(int_filter.Institution.groupby(int_filter.Status).value_counts())\n",
    "result = acceptance_rate[~pd.isnull(acceptance_rate.values)].sort_values(ascending = False)\n",
    "\n",
    "result[:20].plot(kind = 'bar')\n",
    "plt.ylabel('Acceptance Rate (%)')\n",
    "plt.title('Int. Student Acc. Rate for PhD in Biostatistics')\n",
    "plt.rc('xtick', labelsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our process returns a list of 8 colleges that fit this student's criteria, and based on this data, the student stand a good chance of being accepted into the University of Texas School of Public Health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
